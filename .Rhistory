library(tidyverse)
# 1-1) 단순회귀분석 수행하고 그 결과를 간단히 해석
head(mtcars)
mtcars_lm_1 <- lm(mpg ~ wt, data = mtcars)
summary(mtcars_lm_1)
-----------
# 1-1) 단순회귀분석 수행하고 그 결과를 간단히 해석
head(mtcars)
# 차량의 무게(wt)와 주행거리(mpg)와의 관계에 대한 단순 선형 회귀분석을 수행한 결과
#
# (회귀계수의 유의성 검정(t 검정) ) wt의 회귀계수 β1β1 (-5.3445)의 경우, p-value = 1.29e-10 < 0.05이므로 통계적으로 유의함
# (결정계수 해석) 결정계수(Adjusted R2R2)의 값이 0.74인데, 이는 이 선형회귀모델이 데이터를 약 74% 설명하고 있다고 할 수 있음
# (모형의 유의성 검정) F-검정 통계량의 p-value = 1.294e-10 < 0.05 이므로 이 선형회귀모델은 통계적으로 유의한 모델이라고 할 수 있음
-----------
# 1-2) 다중 선형 회귀분석을 수행하고, 그 결과를 간단히 해석
mtcars_lm_2 <- lm(mpg ~ wt + hp, data = mtcars)
summary(mtcars_lm_2)
# 차량의 무게(wt)와 주행거리(mpg)와의 관계에 대한 단순 선형 회귀분석을 수행한 결과
#
# (회귀계수의 유의성 검정(t 검정) ) wt의 회귀계수 β1β1 (-5.3445)의 경우, p-value = 1.29e-10 < 0.05이므로 통계적으로 유의함
# (결정계수 해석) 결정계수(Adjusted R2R2)의 값이 0.74인데, 이는 이 선형회귀모델이 데이터를 약 74% 설명하고 있다고 할 수 있음
# (모형의 유의성 검정) F-검정 통계량의 p-value = 1.294e-10 < 0.05 이므로 이 선형회귀모델은 통계적으로 유의한 모델이라고 할 수 있음
-----------
# 1-2) 다중 선형 회귀분석을 수행하고, 그 결과를 간단히 해석
mtcars_lm_2 <- lm(mpg ~ wt + hp, data = mtcars)
# 1-2) 다중 선형 회귀분석을 수행하고, 그 결과를 간단히 해석
mtcars_lm_2 <- lm(mpg ~ wt + hp, data = mtcars)
# 1-2) 다중 선형 회귀분석을 수행하고, 그 결과를 간단히 해석
mtcars_lm_2 <- lm(mpg ~ wt + hp, data = mtcars)
# 1-2) 다중 선형 회귀분석을 수행하고, 그 결과를 간단히 해석
mtcars_lm_2 <- lm(mpg ~ wt + hp, data = mtcars)
summary(mtcars_lm_2)
# 1-3) 1)과 2) 모형 중 어느 모형이 더 유의적인지 ANOVA을 이용하여 검정
anova(mtcars_lm_1, mtcars_lm_2)
head(mtcars)
mtcars_lm_1 <- lm(mpg ~ wt, data = mtcars)
summary(mtcars_lm_1)
# 1-2) 다중 선형 회귀분석을 수행하고, 그 결과를 간단히 해석
mtcars_lm_2 <- lm(mpg ~ wt + hp, data = mtcars)
summary(mtcars_lm_2)
# 1-3) 1)과 2) 모형 중 어느 모형이 더 유의적인지 ANOVA을 이용하여 검정
anova(mtcars_lm_1, mtcars_lm_2)
mtcars_lm_3 <- lm(scale(mpg) ~ scale(wt) + scale(hp), data = mtcars)
summary(mtcars_lm_3)
mtcars_lm_3 <- lm(scale(mpg) ~ scale(wt) + scale(hp), data = mtcars)
summary(mtcars_lm_3)
# 1-5) 2) 모형의 잔차그림을 그리고 특정한 패턴이 있는지 확인, 그리고 교호작용을 고려한 모형을 적합 후 그 분석결과에 대해 잔차그림을 그려 특정한 패턴이 존재하는지 확인
plot(mtcars_lm_2, which = 1)
mtcars_lm_4 <- lm(mpg ~ wt*hp, data = mtcars)
summary(mtcars_lm_4)
plot(mtcars_lm_4, which=1)
newdata <- data.frame(wt = 3.5, hp = 170)
predict(mtcars_lm_2, newdata, interval="prediction", level = 0.90)
read.csv("gas_price.csv")
read.csv("gas_prices.csv")
getwd()
read.csv("gas_prices.csv")
read.csv("gas_prices.csv")
library(tidyverse)
pgfull <- read.delim("~/pgfull.txt")
View(pgfull)
head(pgfull)
pgfull[, 1:54]
pgfull_1 <- pgfull[, 1:54]
str(pgfull)
summary(pgfull)
dim(pgfull)
dim(pgfull_1)
pgfull_1.pca <- prcomp(pgfull_1, center = T, scale.=T)
pgfull_1.pca
plot(pgfull_1.pca, type = 'l')
## scree plot에 의거 k = 6 으로 선택
summary(pgfull_1.pca)
install.packages("devtools")
library(devtools)
install_github("ggbiplot", "vqv")
library(ggbiplot)
g <- ggbiplot(pgfull_1.pca, obs.scale = 1, var.scale = 1,
groups = pgfull_1.species, ellipse = T,
circle = T)
head(pgfull)
pgfull.species <- pgfull[, 57]
pgfull.species
type(pgfull.species)
asfactor(pgfull.species)
as.factor(pgfull.species)
pgfull.species <- as.factor(pgfull.species)
g <- ggbiplot(pgfull_1.pca, obs.scale = 1, var.scale = 1,
groups = pgfull_1.species, ellipse = T,
circle = T)
g <- ggbiplot(pgfull_1.pca, obs.scale = 1, var.scale = 1,
groups = pgfull.species, ellipse = T,
circle = T)
g <- g + scale_color_dicrete(name = "")
g <- g + scale_color_discrete(name = "")
g <- g + theme(legend.direction = "horizontal",
legend.position = "top")
print(g)
head(pgfull_1)
pgfull_1.scaled <- scale(pgfull_1)
head(pgfull_1.scaled)
pgfull_1.scaled <- scale(pgfull_1)
pgfull.species
wssplot <- function(data, nc = 15, seed = 1234) {
wss <- (nrow(data) - 1) * sum(apply(data, 2, var))
for (i in 2:nc) {
set.seed(seed)
wss[i] <- sum(kmeans(data, centers = i)$withinss)}
plot(1:nc, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within Groups Sum of Squares") }
wssplot(pgfull_1.scaled, nc = 10)
wssplot(pgfull_1.scaled, nc = 15)
wssplot <- function(data, nc = 40, seed = 1234) {
wss <- (nrow(data) - 1) * sum(apply(data, 2, var))
for (i in 2:nc) {
set.seed(seed)
wss[i] <- sum(kmeans(data, centers = i)$withinss)}
plot(1:nc, wss, type = "b",
xlab = "Number of Clusters",
ylab = "Within Groups Sum of Squares") }
wssplot(pgfull_1.scaled, nc = 30)
wssplot(pgfull_1.scaled, nc = 35)
wssplot(pgfull_1.scaled, nc = 40)
wssplot(pgfull_1.scaled, nc = 15)
wssplot(pgfull_1.scaled, nc = 6)
pgfull_1.kmeans <- kmeans(pgfull_1.scaled, 3)
pgfull_1.kmeans$centers
pgfull_1.kmeans$cluster
gas_prices <- read.csv("gas_prices.csv")
head(gas_prices)
# 필요한 데이터만 선택
dim(gas_prices)
gas_prices[, c(14, 15)]
gas_prices_1 <- gas_prices[, c(14, 15)]
str(gas_prices_1)
m <- lm(average ~ index, data = gas_prices_1)
summary(m)
summary(gas_prices_1)
str(gas_prices_1)
m <- lm(average ~ index, data = gas_prices_1)
summary(m)
resids <- rstandard(m)
shapiro.test(resids)
plot(m, which = 2)
# 14.
# part a)
set.seed(1)
x1 = runif(100)
x2 = .5*x1 + rnorm(100)/10
y = 2 + 2*x1 + .3*x2 + rnorm(100)
# part g)
summary(x1)
summary(x2)
x1 = c(x1, .1)
x2 = c(x2, .8)
y = c(y, 6)
par(mfrow=c(2,2))
lm.fit4 = lm(y ~ x1 + x2)
summary(lm.fit4)
windows()
plot(lm.fit4)
par(mfrow=c(2,2))
plot(lm.fit4)
lm.fit5 = lm(y ~ x1)
summary(lm.fit5)
plot(lm.fit5)
lm.fit6 = lm(y ~ x2)
summary(lm.fit6)
plot(lm.fit6)
# part a)
data(Boston)
# part a)
library(ISLR)
data(Boston)
library(MASS)
data(Boston)
attach(Boston)
names(Boston)
str(Boston)
sim_beta_js = c()
names(Boston)[-1]
subset(Boston, select='zn')
t(subset(Boston, select='zn')_
t(subset(Boston, select='zn'))
c(t(subset(Boston, select='zn')))
sim_beta_js = c()
for (name in names(Boston)[-1]) {
predictor = c(t(subset(Boston, select = name)))
lm.fit = lm(crim ~ predictor)
sim_beta_js <- c(sim_beta_js, coef(lm.fit)[2])
print(paste('Runnning simple linear regression : ', name))
print(summary(lm.fit))
}
lm.fit = lm(crim~., data=Boston)
summary(lm.fit)
# part c)
# Results in (b) have much more predictors which are not statistically significant
# comparing to the reult in (a)
sim_beta_js
coef(lm.fit)
coef(lm.fit)[-1]
plot(sim_beta_js, coef(lm.fit)[-1])
par(mfrow=c(1,1))
plot(sim_beta_js, coef(lm.fit)[-1])
# part c)
# Results in (b) have much more predictors which are not statistically significant
# comparing to the reult in (a)
sim_beta_js # :: univariate regression coefficients
names(Boston)
which.max(sim_beta_js)
names(Boston)[which.max(sim_beta_js) + 1]
coef(lm.fit)[which.max(sim_beta_js) + 1]
max(sim_beta_js)
for (name in names(Boston)[-1]){
predictor = c(t(subset(Boston, select=name)))
lm.fit = lm(crim ~ predictor + I(predictor^2) + I(predictor^3)) # adding non-linearity
print(paste('Running simple linear regression on:', name))
print(summary(lm.fit))
}
range(cust_prod_total_freq_15_amt_100$amt)
# make new var with bodyfat dataset by binning
# data loading
# install.packages('mfp')
library(mfp)
data(bodyfat)
glimpse(bodyfat);
bodyfat$bmi <- (bodyfat$weight*.45) / ((bodyfat$height * .02)^2)
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest')
lapply(Packages, library, character.only=T)
# make new var with bodyfat dataset by binning
# data loading
# install.packages('mfp')
library(mfp)
data(bodyfat)
glimpse(bodyfat);
bodyfat$bmi <- (bodyfat$weight*.45) / ((bodyfat$height * .02)^2)
bodyfat$bmi.bins <- cut(bodyfat$bmi,
c(0,25,30,200),
include.lowest = T,
labels=c('normal', 'overweight', 'obese'))
glimpse(bodyfat); levels(bodyfat$bmi.bins)
# loading data
# binning bt time
tran <- read.csv('./data/transaction.csv', stringsAsFactors = F)
rename(tran, hour = time) -> tran # colnames(tran)[which(names(tran) == "time")] <- "hour"와 같은 의미
head(tran)
# loading data
# binning bt time
tran <- read.csv('./data/transaction.csv', stringsAsFactors = F)
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest')
setwd("C:/Users/Daniel/ADP_performance_test")
getwd()
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest')
lapply(Packages, library, character.only=T)
# make new var with bodyfat dataset by binning
# data loading
# install.packages('mfp')
library(mfp)
data(bodyfat)
glimpse(bodyfat);
bodyfat$bmi <- (bodyfat$weight*.45) / ((bodyfat$height * .02)^2)
bodyfat$bmi.bins <- cut(bodyfat$bmi,
c(0,25,30,200),
include.lowest = T,
labels=c('normal', 'overweight', 'obese'))
glimpse(bodyfat); levels(bodyfat$bmi.bins)
# loading data
# binning bt time
tran <- read.csv('./data/transaction.csv', stringsAsFactors = F)
rename(tran, hour = time) -> tran # colnames(tran)[which(names(tran) == "time")] <- "hour"와 같은 의미
head(tran)
tran$hour <- as.numeric(substr(tran$hour, 1, 2))
glimpse(tran)
# h_bin
tran %>% mutate(h_bin = cut(hour,
breaks = c(0, 6, 12, 18, 23),
include.lowest = T, # 0을 그룹에 포함시키기 위해 반드시 필요, 아니면 NA값 반환됨.
labels=c('0-5', '6-11', '12-17', '18-23'))) -> tran
head(tran)
##with gapminder dataset
# install.packages('gapminder')
library(gapminder)
data("gapminder"); glimpse(gapminder)
unique(gapminder$country)
gapminder %>% filter(country == 'Korea, Rep.' & year==2007)
gapminder %>% arrange(year, country)
## 요약 통계량 출력하기
gapminder %>%
summarise(n_obs = n(),
n_countries = n_distinct(country),
n_years = n_distinct(year),
med_gdpc = median(gdpPercap),
max_gdppc = max(gdpPercap))
## 변수변환 > 컬럼추가하기(mutate())
gapminder %>%
mutate(total_gdp = pop*gdpPercap,
le_gdp_ratio = lifeExp / gdpPercap,
lgrk = le_gdp_ratio*100)
# 그룹연산
gapminder %>%
filter(year==2007) %>%
group_by(continent) %>%
summarise(n(), mean(lifeExp), median(lifeExp)) %>%
arrange(-`median(lifeExp)`)
# 요약통계량, 상관관계
summary(gapminder)
summary(gapminder$gdpPercap)
cor(gapminder$gdpPercap, gapminder$lifeExp)
plot(gapminder$gdpPercap, gapminder$lifeExp, cex=.5)
plot(log10(gapminder$gdpPercap), gapminder$lifeExp, cex=.5)
## with df_imdb dataset
df_imdb <- read_csv('./data/imdb-5000-movie-dataset.zip'); glimpse(df_imdb)
df_imdb %>% count(country) %>% arrange(-n)
## 미국 영화의 예산 분포 알아보기
df_imdb %>%
filter(country == 'USA') %>%
ggplot(aes(budget)) + geom_histogram()
df_imdb %>%
group_by(title_year) %>%
summarise(avg_imdb_score = mean(imdb_score)) %>%
ggplot(aes(title_year, avg_imdb_score)) + geom_point() + geom_line()
# 각 facter 별 갯수 및 percentage 확인
data(diamonds)
diamonds %>%
group_by(cut) %>%
tally() %>%
mutate(pct = round((n/sum(n))*100, 1))
cor(gapminder$gdpPercap, gapminder$lifeExp)
cor(gapminder$gdpPercap, gapminder$lifeExp)
cor(log10(gapminder$gdpPercap), gapminder$lifeExp)
# 데이터에 따른 시각화
# 1. 하나의 연속형(히스토그램)
hist(gapminder$lifeExp)
hist(gapminder$gdpPercap, nclass=50)
hist(log10(gapminder$gdpPercap), nclass=50)
gapminder %>%
ggplot(aes(gdpPercap)) + geom_histogram() + scale_x_log10()
gapminder %>%
ggplot(aes(x=gdpPercap, y=lifeExp)) + geom_point() +scale_x_log10() + geom_smooth()
# 2. 하나의 범주형 (막대그래프, 분할표) > 카이제곱 검정
diamonds %>% ggplot(aes(cut)) + geom_bar() # 품질별 개수
table(diamonds$cut)
prop.table(table(diamonds$cut))
round(prop.table(table(diamonds$cut)) * 100, 1)
head(table(survey$W.Hnd))
data(survey)
library(MASS)
data(survey)
head(table(survey$W.Hnd))
data(survey); glimpse(survey)
head(table(survey$W.Hnd))
chisq.test(table(survey$W.Hnd), p=c(.3, .7))
round(prop.table(table(diamonds$cut)) * 100, 1)
# 3. 두 수량형 변수 (산점도)
pairs(diamonds %>% sample_n(1000))
# 3. 두 수량형 변수 (산점도)
pairs(diamonds %>% sample_n(100))
ggpairs(diamonds %>% sample_n(100))
# 4. 수량형 ~ 범주형 (박스플롯)
mpg %>%
ggplot(aes(class, hwy)) + geom_boxplot()
mpg %>%
mutate(class=reorder(class, hwy))
mpg %>%
mutate(class=reorder(class, hwy, median))
mpg %>%
mutate(class=reorder(class, hwy, median)) %>% # hwy의 중간값 순서로 정렬
ggplot(aes(class, hwy)) + geom_jitter() + geom_boxplot(alpha=.5)
mpg %>%
mutate(class=factor(class,
levels=c('2seater', 'subcompact', 'compact', 'midsize',
'minivan', 'suv', 'pickup'))) %>% ## 순서 직접 지정
ggplot(aes(class, hwy)) + geom_jitter() + geom_boxplot(alpha=.5)
# 4. 범주형 ~ 범주형 (분할표 / 모자이크) > 카이제곱 검정
fread('./data/titanic3.csv', data.table = F)
# 4. 범주형 ~ 범주형 (분할표 / 모자이크) > 카이제곱 검정
fread('./data/titanic3.csv', data.table = F) -> titanic; glimpse(titanic)
xtabs(freq ~ class + sex + age + survived, data.frame(titanic))
xtabs(Freq ~ class + sex + age + survived, data.frame(titanic))
data("Titanic")
data("Titanic"); glimpse(Titanic)
xtabs(~ Class + Sex + Age + Survived, data.frame(Titanic))
xtabs(Freq ~ Class + Sex + Age + Survived, data.frame(Titanic))
xtabs(survived == 'survived' ~ sex + pclass, data=Titanic)
# 4. 범주형 ~ 범주형 (분할표 / 모자이크) > 카이제곱 검정
data("Titanic"); glimpse(Titanic)
as.tibble(fread('./data/titanic3.csv', data.table = F)) -> titanic
as.tibble(fread('./data/titanic3.csv', data.table = F)) -> titanic; glimpse(titanic)
titanic %>%
mutate_if(is.numeric, funs(imp=ifelse(is.na(.), median(., na.rm=T), .))) %>%
mutate_if(is.character, funs(imp=ifelse(is.na(.), "NA", .)))-> t_tmp; summary(t_tmp)
titanic$pclass <- as.factor(titanic$pclass)
titanic$ticket <- as.character(titanic$ticket)
titanic$survived <- factor(titanic$survived, levels=c(0,1), labels=c('dead', 'survived'))
glimpse(titanic)
as.tibble(fread('./data/titanic3.csv', data.table = F)) -> titanic; glimpse(titanic)
titanic %>% replace(is.na(.), 0) -> titanic
titanic$pclass <- as.factor(titanic$pclass)
titanic$ticket <- as.character(titanic$ticket)
titanic$survived <- factor(titanic$survived, levels=c(0,1), labels=c('dead', 'survived'))
glimpse(titanic)
titanic$sex <- as.factor(titanic$sex)
glimpse(titanic)
xtabs(survived == 'survived' ~ sex + pclass, data=titanic)
xtabs(survived == 'survived' ~ sex + pclass, data=titanic) / xtabs(~ sex + pclass, data=titanic)
# 성별과 사망률이 독립인지?
chisq.test(~ sex + survived, data=titanic)
# 성별과 사망률이 독립인지?
chisq.test(xtabs(~ sex + survived, data=titanic))
# mosaic plot----
mosaicplot(survived ~ pclass + sex, data = titanic, color=T)
head(tran)
# hour bin을 one-hot coding
tran <- dummy.data.frame(tran, names=c('h_bin'), sep='_')
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest', 'dummies')
lapply(Packages, library, character.only=T)
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest', 'dummies')
lapply(Packages, library, character.only=T)
install.packages('party')
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest', 'dummies')
lapply(Packages, library, character.only=T)
install.packages('TH.data')
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest', 'dummies')
lapply(Packages, library, character.only=T)
# h_bin one-hot coding
tran <- dummy.data.frame(tran, names=c('h_bin'), sep='_')
head(tran,20)
# loading data
# binning bt time
tran <- read.csv('./data/transaction.csv', stringsAsFactors = F)
rename(tran, hour = time) -> tran # colnames(tran)[which(names(tran) == "time")] <- "hour"와 같은 의미
head(tran)
tran$hour <- as.numeric(substr(tran$hour, 1, 2))
glimpse(tran)
# h_bin
tran %>% mutate(h_bin = cut(hour,
breaks = c(0, 6, 12, 18, 23),
include.lowest = T, # 0을 그룹에 포함시키기 위해 반드시 필요, 아니면 NA값 반환됨.
labels=c('0-5', '6-11', '12-17', '18-23'))) -> tran
head(tran)
unique(tran$h_bin)
# h_bin one-hot coding
tran <- dummy.data.frame(tran, names=c('h_bin'), sep='_')
head(tran,20)
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid, `h_bin_6-11`, `h_bin_12-17`, `h_bin_18-23`) -> df_h
# 고객별 구매시간 bin들의 합 구하기
df_h %>% group_by(custid) %>%
summarise(sum.h_6_11 = sum(`h_bin_6-11`),
sum.h_12_17 = sum(`h_bin_12-17`),
sum.h_18_23 = sum(`h_bin_18-23`)) -> cust_visit_h
# h_bin one-hot coding
tran <- dummy.data.frame(tran, names=c('h_bin'), sep='_')
head(tran,20)
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid, `h_bin_6-11`, `h_bin_12-17`, `h_bin_18-23`) -> df_h
head(tran,20)
colnames(tran)
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid, `h_bin_6-11`, `h_bin_12-17`, `h_bin_18-23`) -> df_h
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid, h_bin_6-11, h_bin_12-17, h_bin_18-23) -> df_h
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid, `h_bin_6-11`, `h_bin_12-17`, `h_bin_18-23`) -> df_h
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid)
setwd("C:/Users/Daniel/ADP_performance_test")
getwd()
Packages <- c('tidyverse', 'data.table', 'reshape2', 'caret', 'rpart', 'GGally', 'ROCR', 'party',
'randomForest', 'dummies')
lapply(Packages, library, character.only=T)
# make new var with bodyfat dataset by binning
# data loading
# install.packages('mfp')
library(mfp)
# loading data
# binning bt time
tran <- read.csv('./data/transaction.csv', stringsAsFactors = F)
rename(tran, hour = time) -> tran # colnames(tran)[which(names(tran) == "time")] <- "hour"와 같은 의미
head(tran)
tran$hour <- as.numeric(substr(tran$hour, 1, 2))
glimpse(tran)
# h_bin
tran %>% mutate(h_bin = cut(hour,
breaks = c(0, 6, 12, 18, 23),
include.lowest = T, # 0을 그룹에 포함시키기 위해 반드시 필요, 아니면 NA값 반환됨.
labels=c('0-5', '6-11', '12-17', '18-23'))) -> tran
head(tran)
unique(tran$h_bin) # '0-5' 시간대가 없음에 유의
# h_bin one-hot coding
tran <- dummy.data.frame(tran, names=c('h_bin'), sep='_')
colnames(tran)
head(tran,20)
# 고객별 구매시간 비율을 알아보기 위해 필요한 변수만 선택
tran %>% select(custid)
